{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpData():\n",
    "    datMat = matrix([[1. , 2.1],\n",
    "                    [2. , 1.1],\n",
    "                    [1.3, 1. ],\n",
    "                    [1. ,1. ],\n",
    "                    [2. ,1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat, classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotDataSet(datMat,classLabels):\n",
    "    xcord0 = []\n",
    "    ycord0 = []\n",
    "    xcord1 = []\n",
    "    ycord1 = []\n",
    "    markers =[]\n",
    "    colors =[]\n",
    "\n",
    "    for i in range(len(classLabels)):\n",
    "        if classLabels[i]==1.0:\n",
    "            xcord1.append(datMat[i,0]), ycord1.append(datMat[i,1])\n",
    "        else:\n",
    "            xcord0.append(datMat[i,0]), ycord0.append(datMat[i,1])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)       \n",
    "    ax.scatter(xcord0,ycord0, marker='s', s=90)\n",
    "    ax.scatter(xcord1,ycord1, marker='o', s=50, c='red')\n",
    "    plt.title('decision stump test data')\n",
    "    plt.show()\n",
    "\n",
    "datMat,classLabels = loadSimpData()\n",
    "plotDataSet(datMat,classLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成单层决策树\n",
    "1. 第一个函数用于测试是否有某个值小于或者大于我们正在测的阈值\n",
    "2. 第二个函数会在一个加权数据集中循环，并找到具有最低错误率的单层决策树\n",
    "\n",
    "    * 将最小错误率minError设为正无穷大\n",
    "    * 对数据集中的每一个特征（第一层循环）：\n",
    "        * 对每个步长（第二次循环，用于确定阈值）:\n",
    "            * 对每个不等号：\n",
    "                * 建立一棵单层决策树并利用加权数据集及对它进行测试\n",
    "                * 如果错误率低于minError，则将当前单层决策树设为最佳单层决策树\n",
    "    * 返回最佳单层决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "    '''通过阈值比较对数据进行分类，所有不满足不等式的都被设置为-1，其他的被设置为1'''\n",
    "    \n",
    "    retArray = ones((shape(dataMatrix)[0],1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr,classLabels,D):\n",
    "    '''遍历stumpClassify()函数所有的可能输入值，并找到数据集上最佳的单层决策树。'''\n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T                #输入数据集 M * N ，标签 M * 1\n",
    "    m,n = shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))        #设定步长调整的次数，建立用于存储最好决策树的字典，最好分类预测结果\n",
    "    minError = inf                                                          #初始化最小误差为无穷大\n",
    "    \n",
    "    for i in range(n):\n",
    "        '''在数据集的所有特征上遍历'''\n",
    "        rangeMin = dataMatrix[:,i].min();rangeMax = dataMatrix[:,i].max()    #计算每一个特征的最小值和最大值\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps                              #计算最大步长\n",
    "        \n",
    "        for j in range(-1,int(numSteps)+1): \n",
    "            '''调整阈值'''\n",
    "            for inequal in ['lt','gt']:\n",
    "                threshVal = (rangeMin+float(j)*stepSize)                         #计算阈值\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)    #根据维度和阈值，预测标签\n",
    "                # print(predictedVals)\n",
    "\n",
    "                errArr = mat(ones((m,1)))                                        #初始化误差矩阵为1，若预测和标签相等则设为0\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr                                       #计算加权错误率\n",
    "                print('split dim: %d, %s than the thresh %.2f, the weighted error is %.3f' % (i, inequal,threshVal, weightedError))\n",
    "\n",
    "                if weightedError<minError:                                       #找到使得加权错误率最小的阈值和维度\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['ineq'] = inequal\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                \n",
    "    return bestStump,minError,bestClasEst                                    #返回最好的树结构，最小的加权错误率和预测标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split dim: 0, lt than the thresh 0.90, the weighted error is 0.400\n",
      "split dim: 0, gt than the thresh 0.90, the weighted error is 0.600\n",
      "split dim: 0, lt than the thresh 1.00, the weighted error is 0.400\n",
      "split dim: 0, gt than the thresh 1.00, the weighted error is 0.600\n",
      "split dim: 0, lt than the thresh 1.10, the weighted error is 0.400\n",
      "split dim: 0, gt than the thresh 1.10, the weighted error is 0.600\n",
      "split dim: 0, lt than the thresh 1.20, the weighted error is 0.400\n",
      "split dim: 0, gt than the thresh 1.20, the weighted error is 0.600\n",
      "split dim: 0, lt than the thresh 1.30, the weighted error is 0.200\n",
      "split dim: 0, gt than the thresh 1.30, the weighted error is 0.800\n",
      "split dim: 0, lt than the thresh 1.40, the weighted error is 0.200\n",
      "split dim: 0, gt than the thresh 1.40, the weighted error is 0.800\n",
      "split dim: 0, lt than the thresh 1.50, the weighted error is 0.200\n",
      "split dim: 0, gt than the thresh 1.50, the weighted error is 0.800\n",
      "split dim: 0, lt than the thresh 1.60, the weighted error is 0.200\n",
      "split dim: 0, gt than the thresh 1.60, the weighted error is 0.800\n",
      "split dim: 0, lt than the thresh 1.70, the weighted error is 0.200\n",
      "split dim: 0, gt than the thresh 1.70, the weighted error is 0.800\n",
      "split dim: 0, lt than the thresh 1.80, the weighted error is 0.200\n",
      "split dim: 0, gt than the thresh 1.80, the weighted error is 0.800\n",
      "split dim: 0, lt than the thresh 1.90, the weighted error is 0.200\n",
      "split dim: 0, gt than the thresh 1.90, the weighted error is 0.800\n",
      "split dim: 0, lt than the thresh 2.00, the weighted error is 0.600\n",
      "split dim: 0, gt than the thresh 2.00, the weighted error is 0.400\n",
      "split dim: 1, lt than the thresh 0.89, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 0.89, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.00, the weighted error is 0.200\n",
      "split dim: 1, gt than the thresh 1.00, the weighted error is 0.800\n",
      "split dim: 1, lt than the thresh 1.11, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.11, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.22, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.22, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.33, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.33, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.44, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.44, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.55, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.55, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.66, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.66, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.77, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.77, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.88, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.88, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 1.99, the weighted error is 0.400\n",
      "split dim: 1, gt than the thresh 1.99, the weighted error is 0.600\n",
      "split dim: 1, lt than the thresh 2.10, the weighted error is 0.600\n",
      "split dim: 1, gt than the thresh 2.10, the weighted error is 0.400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datMat, classLabels = loadSimpData()\n",
    "D = mat(ones((5,1))/5)\n",
    "buildStump(datMat,classLabels,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整AdaBoost 算法实现\n",
    "伪代码\n",
    "* 对每次迭代：\n",
    "    * 利用 buildStump() 函数找到最佳的单层决策树\n",
    "    * 将单层决策树加入到单层决策树数组\n",
    "    * 计算 单层决策树分类器对应的权重alpha\n",
    "    * 计算新的数据权重 D\n",
    "    * 更新累计类别估计值\n",
    "    * 如果错误率等于0，则退出循环   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    weakClassArr = []                                                  # 初始化弱分类器数组\n",
    "    m = shape(dataArr)[0];    D = mat(ones((m,1))/m)                   # 初始化数据权重\n",
    "    aggClassEst = mat(zeros((m,1)))                                    # 初始化累计预测值\n",
    "    \n",
    "    for i in range(numIt):                                              \n",
    "        bestStump, error, classEst = buildStump(dataArr,classLabels,D) # 找到加权误差率最小的的决策树\n",
    "        # print('D:',D.T)\n",
    "        # print('classEst',classEst.T)\n",
    "        \n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))           # 计算分类器权重           \n",
    "        #print('alpha:',alpha)\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        \n",
    "        \n",
    "        expon = multiply(-1*alpha*mat(classLabels).T, classEst)        #  更新 数据权重 D = D * exp(-alpha * yi * G(xi)) / D.sum()\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        \n",
    "        aggClassEst += alpha*classEst                                  # 累计预测值\n",
    "        #print('aggClassEst:',aggClassEst.T)\n",
    "        \n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m                                  # 计算多个分类器组合之后的错误率\n",
    "        print('total error:',errorRate)\n",
    "        \n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "            \n",
    "    return weakClassArr         # 返回弱分类器数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.2\n",
      "total error: 0.2\n",
      "total error: 0.0\n",
      "[{'dim': 0, 'ineq': 'lt', 'thresh': 1.3, 'alpha': 0.6931471805599453}, {'dim': 1, 'ineq': 'lt', 'thresh': 1.0, 'alpha': 0.9729550745276565}, {'dim': 0, 'ineq': 'lt', 'thresh': 0.9, 'alpha': 0.8958797346140273}]\n"
     ]
    }
   ],
   "source": [
    "classifierArr = adaBoostTrainDS(datMat,classLabels,9)\n",
    "print(classifierArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用训练好的 AdaBoost 分类器进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = mat(datToClass)\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],classifierArr[i]['thresh'], classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst \n",
    "        #print('aggClassEst:',aggClassEst)\n",
    "    \n",
    "    return sign(aggClassEst)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0,0],classifierArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用 AdaBoost 算法预测患有疝病的马是否能够存活"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    datMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curline = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curline[i]))\n",
    "        datMat.append(lineArr)\n",
    "        labelMat.append(float(curline[-1]))\n",
    "    return datMat, labelMat        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.2842809364548495\n",
      "total error: 0.2842809364548495\n",
      "total error: 0.24749163879598662\n",
      "total error: 0.24749163879598662\n",
      "total error: 0.25418060200668896\n",
      "total error: 0.2408026755852843\n",
      "total error: 0.2408026755852843\n",
      "total error: 0.22073578595317725\n",
      "total error: 0.24749163879598662\n",
      "total error: 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "datArr, labelArr = loadDataSet(r'data/horseColicTraining2.txt')\n",
    "# print(labelArr)                                                 # 标签必须为 1.0 和 -1.0\n",
    "weakclassEst = adaBoostTrainDS(datArr, labelArr,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datArr, labelArr = loadDataSet(r'data/horseColicTest2.txt')\n",
    "prediction = adaClassify(datArr, weakclassEst)\n",
    "# print(prediction)\n",
    "errArr = mat(ones((67,1)))\n",
    "errArr[prediction != mat(labelArr).T].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROC(predStrengths, classLabels):\n",
    "    cur = (1.0,1.0)\n",
    "    ySum = 0.0\n",
    "    numPosClas = sum(array(classLabels)==1.0)\n",
    "    yStep = 1/float(numPosClas)\n",
    "    xStep = 1/float(len(classLabels)-numPosClas)\n",
    "    \n",
    "    sortedIndicies = predStrengths.argsort()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.clf()\n",
    "    \n",
    "    ax = plt.subplot(111)\n",
    "    for index in sortedIndicies.toList():\n",
    "        if classLabels[index] == 1.0:\n",
    "            delX = 0; delY = yStep;\n",
    "        else:\n",
    "            delX = xStep;delY = 0;\n",
    "        ySum += cur[1]\n",
    "        \n",
    "        ax.plot([cur[0],cur[0]-delX], [cur[1], cur[1]-delY], c='b')\n",
    "        cur = (curp[0]-delX, cur[1]-delY)\n",
    "    \n",
    "    ax.plot([0,1],[0,1],'b--')\n",
    "    plt.xlabel('False Positive'); plt.ylabel('True Positive')\n",
    "    plt.title('ROC')\n",
    "    ax.axis([0.1,0.1])\n",
    "    plt.show()\n",
    "    print('the Area Under the curve is:', ySum*xStep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
